GNATS file for stenglib/.

S. Engblom 2026-01-08 (Latest revision)

----------------------------------------------------------------
Ideas:

* Tensor/tpermute: works like PERMUTE but allows dimensions to be equal:
    D = tpermute(A,[1 1])   % D = diag(A)
    D = tpermute(A,[3 3])   % D = reshape(diag(A),1,1,[])
    D = tpermute(A,[2 1 1]) % D(i,j) = A(j,i,i)

  If tpermute is used by tprod, then one can allow multiple
  indices:
    S = tprod(A,A,[-1 -1],[-1 -1]) % S = diag(A)'*diag(A)

* Tensor/uniqueix: find unique indices.
    [I1,I2,...] = UNIQUEIX(SZ) returns indices into an imagined array A of 
    dimensions SZ such that all I1 >= I2 >= ...

    Example:
      A = rand(8);
      [i,j] = uniqueix(size(A)); % same as [i,j] = find(tril(A))

      % instead of using SUB2IND to get linear index you may use
      ix = clenshaw([1 size(A,1)]',0,[i j]'-1)+1 % same as ix = find(tril(A))

    See also NCHOOSEK, SUB2IND, IND2SUB.

  This is useful for handling indices in various codes.

----------------------------------------------------------------
Guidelines:

* Negative tests should test the error generated by checking the 
  message-id. Otherwise it is difficult to see that the correct errors 
  are generated.

* (C-code) Use Matlabs automatical deallocation mechanism when errors
  are issued. -At least if in this way lots of code to deallocate many
  variables is avoided. There is no need for performance when the
  input is wrong.

* (C-code) Use mxRealloc() to avoid allocating and copying arrays when
  the result is already in the memory. Prefer to use mxRealloc() and
  mxSetPr() instead of a new allocation followed by memcpy(). However,
  this construction must excercise CAUTION and account for the
  possibility that mxRealloc() fails!

* Avoid allocating small arrays for, e.g., dimension vectors. They can
  be static instead since an array of 1M dimensions or so is quite
  unlikely.

* All functions in Fast should be completely independent of all
  functions in Tensor, and vice versa. This should hold both in tests,
  examples and references of any kind. Functions in Utils may depend
  on any function, even on other functions in Utils.

* Categories of tests:
  checkin : Very small tests mainly to check dependencies.
  spin       : Fast but genuine tests of as many cases as possible.
  scrub     : Slower tests that excercises many functions at once.
  bench    : Test of performance and memory.

----------------------------------------------------------------
Fixes/Suggestions:

* fsparse.c: Is not completely fixed for the -largeArrayDims.
  Update: an issue was filed on this:
  --
  "When generating large matrices it can happen that the number of
  elements is larger then the max value that can be stored in "int"
  format. If this happens I use the workaround below to generate the
  matrix in multiple steps. However this is not ideal. Can the "int"
  limitation be changed into "long" or would this result in other
  problems?"
  --
  Problem: can not easily verify the behavior here, so not easy to develop.
  >> intmax('int32')
  >> fsparse(ones(1,2e7),ones(1,2e7),1,[1 1])
  >> fsparse(ones(1,2e8),ones(1,2e8),1,[1 1])
  >> fsparse(ones(1,2e9),ones(1,2e9),1,[1 1])
  
* fsparse.c: sparse_nosort(), gsparse() and gsparse_nosort() contain
  defines. Decision?

* fsparse.c: Would be nice with a 'unique' version. That is, the input
  is considered unique (and in order).

* fsparse.c: A useful and convenient syntax is the syntax supported by
  spdiags. How about adding it to fsparse?
    S = FSPARSE('diag',A,d,[M N Nzmax]); % SIZ is optional

* Functions in Tensor and Fast could use a small header for certain
  common macros, e.g., stenglib_util.h.

* Functions in Utils does not implement the stronger standard for
  errors. Neither are errors tested.
  -Partial fix in that errors for ndop are checked.

* ndop.m: Change the definition of scaling so that it could be an
  N-dimensional array with dimensions matching that of the
  computational domain SZ (or singletons).

* spym.m: Should make a coarse-grain version of a too large sparse matrix.

* tprod.c/tsum.c: Optimize away some permutations! -Negative indices
  need only be sorted in the *same* order, not neccessarily in
  *increasing* order. -Use the "T"/"N"-option to dgemm() whenever
  possible to simplify the permutations. This is similar to what
  Matlab does.

* tprod.c/tsum.c: Why not allow the positive indices to be
  non-contiguous? This avoids using permute afterwards in some
  cases. Example: tprod(A,B,[-1 2 3 4],[4 3 2 -1]) =
  permute(tprod(A,B,[-1 1 2 3],[3 2 1 -1]),[4 1 2 3]).

----------------------------------------------------------------
Minor bugs/Fixes:

* Use matlabroot in make. Also: -O3!

* Include (halton.m, rconv.m?) into SciComp. And spectralcode to
  SciComp (gausspd, gaussqd). Move consistency and stability to Utils.
  -Moved consistency and stability to Utils.

* Fast/sppmul.c and powerseries.c are not tested.

* Scicomp/nmsimplex.m, rtsafe.m and ainsolve.m are not tested.

* clenshaw.c, mexfrepmat.c, tprod.c, tsum.c (...): Add tests in scrub
  for the boundary cases when the output is so large it won't fit into
  a matrix or when certain integer computations will swap. Sometimes
  this is ok naturally (e.g. when allocating the end-result early in
  the routine), sometimes not.

* tsum.c, clenshaw.c: Uses mxRealloc() in a possibly dangerous way.

* spym.m: Works somewhat ugly for sparse matrices and for large dense
  matrices. Some kind of sparsification should be supported.
  Example:
    % the following sums each 10-by-10 block in S without switching to
    % a full matrix
    S = sprand(100,100,0.15);
    T = sum(reshape(S,10,[]),1);
    T = sum(reshape(reshape(T,10,[]).',10,[]),1);
    T = reshape(full(T),10,10);
    % now one could use T as an average of S

* frepmat.m: Depends on tsize and tndims so that Fast is dependent on
  Tensor contrary to the guidelines.

* tprod.c/tsum.c: Is too slow for certain products. Using the BLAS-3
  function dgemm() is not always the optimal solution.
  Repeat:
    A = rand(30,30,30,30); B = rand(30,30,30,30);
    t1 = cputime; C1 = tprod(A,B,1:4,1:4); t1 = cputime-t1
    %t1 =
    %   1.74000000000000
    t2 = cputime; C2 = A.*B; t2 = cputime-t2
    %t2 =
    %   0.09999999999999

    k = 10; % try 15...
    A = rand(20,20,20,20,k); B = rand(20,20,20,20,k);
    t1 = cputime; C1 = tprod(A,B,[1:4 -1],[1:4 -1]); t1 = cputime-t1
    t2 = cputime;
    C2 = A(:,:,:,:,1).*B(:,:,:,:,1);
    for i = 2:k, C2 = C2+A(:,:,:,:,i).*B(:,:,:,:,i); end
    t2 = cputime-t2

    k = 10; % try 15...
    A = rand(20,20,20,20,k); B = rand(20,20,20,20,k);
    t1 = cputime; C1 = tprod(A,B,[1:4 5],[1:4 6]); t1 = cputime-t1
    t2 = cputime;
    C2 = zeros(20,20,20,20,k,k);
    for j = 1:k, for i = 1:k
      C2(:,:,:,:,i,j) = A(:,:,:,:,i).*B(:,:,:,:,j);
    end, end
    t2 = cputime-t2

  That is, when the outer (the private) dimension is very large
  compared to the inner (common) dimension, then the loops are
  performed in the wrong order. The complete fix is hairy, but a fix
  for now is to use a hand-made construction when any of the common
  dimensions are singletons (frequent case is that there are no
  negative indices). This is easy.

  The same considerations apply for tsum also, although some
  benchmarks does indicate that the impact is less significant. It is
  fairly easy to design the code so that the innermost loop is
  performed over the maximum span of data.

----------------------------------------------------------------
Medium bugs:


----------------------------------------------------------------
Major bugs:


----------------------------------------------------------------
History:

* search: Works like HISTC but does not produce the histogram count.
  Algorithm: binary search and binary hunt. This is especially fast if
  the input is partially in order.

  Syntax: I = SEARCH(X,T) is about the same as [foo,I] = HISTC(X,T).
  The count could be the optional output number two.
  -Besides hist, there is now also histogram!

* Fast/select: works like a partial SORT and syntactically like FIND:
    [Y,I] = SELECT(X,K,DIM = integer {1},MODE = {'first'} | 'last')
    Y = select(X,K);
      % Y = sort(X); Y = Y(1:K,:,:,...);
    Y = select(X,K,2,'last');
      % Y = sort(X,2); Y = Y(:,end+1-K:end,:,:,...)
    [Y,I] = select(X,K,3,'last');
      % Y = sort(X,3);
      % Y = Y(:,:,end+1-K:end,:,:,...);
      % I = I(:,:,end+1-K:end,:,:,...);
  -Now exists as mink and maxk!

* Use the construction '-DBLASINT=size_t' whenever BLAS-routines are
  called.
  -Done.

* fsetop.c: Why not output also inverse combinations for 'union'
  (not only how to re-assemble C, but also A and B).
  Example:
    [C,IA,IB,JA,JB] = FSETOP('union',A,B) returns the combined columns
    from A and B but with no repetitions. C = [A(:,IA) B(:,IB)], A =
    C(:,JA), B = C(:,JB).

    % equivalent construction:
    C = fsetop('union',A,B);
    [foo,ja] = fsetop('ismember',A,C);
    [foo,jb] = fsetop('ismember',B,C);
  -Implemented.

* fsparse.c: Why the f**k is fsparse *slower* than sparse??? -This
  must be investigated on other platforms, compare Matlab 6.5/7.0.
  Repeat:
    scrub(8:11) % with statistics displayed or using the profiler!
  -Checked Matlab 7.0 under Solaris, Matlab 7.2, 7.8 under mex64, 7.8
  under mexmaci. This seems to be a problem on the (Power-PC) Mac
  only.

* clenshaw.c: The N-D syntax does not seem to be useful. Change the
  'coefficient'-format so that C kan be M-by-(N | 1)-by-K
  instead. This would be useful and is in principle already supported
  by the C-code.
  -N-D syntax removed. C is M-by-(K | 1)-by-(N | 1) and the output is
   K-by-N (one could argue that the output should be N-by-K). To be
   evaluated.

* fsetop.c: Add set-operations on scalar structs. Changes also in
  parseopts.m.
  -Cannot see the point of this.

* spblock.m: Should incorporate fsparse.
  -Fixed.

* ndop.m: Isn't tested for complex input.
  -Fixed. Test added.

* ndop.m: Sometimes the incorrect boundaries are used (see file ndop.m
  for the fix). This has not been tested.
  Repeat:
    S = full(ndop([1; 0],[2 1],[3 3])); % didn't work prior to fix
  -Fixed. Test added.

* ndop.m: When scaling is used, the arguments are evidently not
  checked completely.
  Repeat:
    ndop(1,1,10,[],1:20) % should be an error
  -Fixed. Test added.

* ndop.m: Should work for zero molecule. Fixed but not tested.
  Repeat:
    ndop(0,1,1); % didn't work prior to fix
  -l_spin5 added to spin.

* ndop.m: Should incorporate fsparse, tsize and tndims.
  -Done.

* fsparse.c: Another idea is a third dimension of the input that is
  associated with the value-array. This could be useful for building
  block-matrices although the coding might be difficult!
  Example:
    ii = [[1:5]' [6:10]']; ii = permute(ii,[1 3 2]);
    jj = [1:5; 6:10];      jj = permute(jj,[3 1 2]);
    ss = rand(5,5,5);
    fsparse(ii,jj,ss); % builds two blocks
  -Too complicated and not so useful.

* fsparse.c: Fix squeeze() so that the array is actually
  reallocated. It is nice to guarantee exact allocation.
  -Nice yes, but it doesn't make sense...

* fsparse.c: mx_IsInt() is questionable. -Just ask for int32!
  -Cleaned up, but this was actually good... (100113: Don't remember
  why now...)

* clenshaw.c: Dies for some cases of mismatching dimensions.
  Repeat:
    A = ones(3,100); B1 = ones(3,100); B2 = ones(3,1);
    C = ones(3,3,3,3);
    y = clenshaw({A A A A},{B1 B1 B2 B2},C); % dies
  -Fixed. Tests not added. See new minor bug.

* tsum.c: Seems to have a bug under Solaris, Matlab 7.2.0.283 (R2006a).
  Repeat:
    A = rand(20,20,10,10);
    B = tsum(A,[-1 -2]); % *** crash
  Works under Mac though.
  -Fixed.

* fsetop.c: Add the operation 'hash' (or 'checksum') which computes
  the hash-values only. This is useful for checksums.

  Example:
    % if prod(size(DATA)) is even...
    chk = fsetop('hash',reshape(DATA,[],2)); % 64-bit checksum
  -Operation 'check' added.

* fsetop.c: Add the operation 'find' (or 'find_all') according to
  [IA,IB] = FSETOP('find',A,B) returns index sets IA and IB such that
  A(:,IA) = B(:,IB) and where IA is non-decreasing. This is formally
  not a set-operation since A(:,IA) and B(:,IB) need not be unique.

  Example:
    [ia,ib] = fsetop('find',[1 2 3 4],[1 2 2 3 5 3])
    ia = [1 2 2 3 3];
    ib = [1 2 3 4 6];
    % this is equivalent to
    [IB,IA] = find(fsparse([1:size(B,2)]',1:size(A,2), ...
	      double(~any(tsum(B,-A,[3 1],[3 2]),3))));
    % or as an "outer" equivalence followed by a find
    for i = 1:size(B,2)
      for j = 1:size(A,2)
        T(i,j) = all(B(:,i) == A(:,j));
      end
    end
    [IB,IA] = find(T);
  -Cannot see the usage of this operation.

* fsetop.c: Add set-operations on cell-vectors containing arrays (full
  numerical, character and logical arrays). This complements the
  cell-vector of row-strings now supported and is useful for
  e.g. doing set-operations on index. The best way to implement this
  is probably to write the function

     void hashSort(hashTable *T,
       const mxArray **A,size_t Na,
       const mxArray **B,size_t Nb,size_t Mbytes);

  mxIsEqual() can be used as a way to check for equivalence. Perhaps
  one should also use a special structure mxhashTable instead, with
  pointers to mxArray's instead? This construction avoids the need for
  copying chunks of memory out from and back into cell-vectors. Note
  that the out-functions need to be improved as well.
  -Implemented. Tests added.

* fsetop.c: Possible update of Hsieh's code (time it?):
  (...Code...)
  -Updated.

* fsetop.m: Change 'A(:,IA) = B(:,IB(IB ~= 0))' to 'A(:,IA) =
  B(:,IB(IA))' in the help-text.
  -Changed.

* fsetop.c: Does not work properly for empty arrays.
  Repeat:
    % c should be 0-by-1:
    [c,ia,ib] = fsetop('intersect',zeros(0,5),zeros(0,3));
    [c,ia,ib] = fsetop('union',zeros(0,5),zeros(0,3));
    [b,ia,ib] = fsetop('unique',zeros(0,5)); % crash!!!
    % c should be 0-by-0:
    [c,ia] = fsetop('setdiff',zeros(0,5),zeros(0,3));
    [c,ia,ib] = fsetop('setxor',zeros(0,5),zeros(0,3));
    % ia, ib should contain ones:
    [ia,ib] = fsetop('ismember',zeros(0,5),zeros(0,3));
  -Fixed. Tests added to spin.

* clenshaw.c: Change of syntax? The current approach as for the syntax
  of the recursion is sometimes inconvenient. What about an initial
  1-by-4 array I that works roughly as follow:
    Y(1,j) = I(1)*A(1,j)+I(2)*B(1,j)
    Y(2,j) = I(3)*A(2,j)+I(4)*B(2,j)
    Y(i,j) = Y(i-1,j)*A(i,j)+Y(i-2,j)*B(i,j)
  Elements in I that are not given are considered to be 1 --- or 0?

  Compare:
    % Legendre polynomials
    x = linspace(-1,1); n = 4;
    % current
    j = [0.5 1:n]';
    A = (2*j-1)./j*x;
    B = (1-j)./j;
    Y1 = clenshaw(A,B);
    % new suggestion (not a big difference)
    j = [-1 1:n]';
    A = (2*j-1)./j*x;
    B = (1-j)./j;
    Y2 = clenshaw([0 -0.5],A,B);

    % Chebyshev polynomials
    n = 4; x = linspace(-1,1,50);
    % current syntax
    A = [0; 0.5; ones(n-1,1)]*2*x;
    B = [1; 0; -ones(n-1,1)];
    Y1 = clenshaw(A,B);
    % new suggestion (uses less memory)
    A = 2*x; B = -ones(n,1);
    Y2 = clenshaw([0 -1 0.5 0],A,B);

  -The advantage is not convincing (only really an improvement for
  Chebyshev polynomials!).

* mexfrepmat.c: It seems unnecessary to clear jcB:
    in mexfrepmat.c/sparse_replicate():
      memset(jcB,0,(sizB[1]+1)*sizeof(int)); % L203
  Matlab does this automatically.
  -Done.

* mexfrepmat.c: bool should be used instead of int. Refresh the code
  so it looks like GNU-C99.
  -Changed to bool.

* mexfrepmat.c: It is better so use mxSet-functions when allocating
  sparse matrices. E.g.
    out = mxCreateSparse(0,0,Nzmax,...);
    mxSetM(out,M);
    mxSetN(out,N);
    mxFree(mxGetJc(out));
    mxSetJc(out,jcS);
  -Seems to have been fixed (?).

* mexfrepmat.c: Dies with NaN's.
  Repeat:
    frepmat(1,[1 NaN]);
    frepmat(1,[1 Inf]); % out of memory...
  Related to the above gnats.
  -Fixed. Added test in spin.

* fsparse.c: ii, jj are not explicitly deallocated on error.
  -Not fixed, new guideline.

* fsparse.c: Dies with NaN's.
  Repeat:
    fsparse(1:3,[1 NaN 2],1);
    fsparse(1:3,[1 Inf 2],1); % out of memory...
  Suggested fix: use ceil(ix) != ix for detecting non-integral values:
  ix = [1 2 3 1.1 Inf -Inf NaN -NaN]
  ceil(ix) ~= ix
  ans =
        0 0 0 1   0    0   1    1 
  -Fixed as suggested, tests added to spin. The Inf-case was deemed ok.

* fsparse.c: Sometimes produces an error for empty input.
  Repeat:
    fsparse(ones(1,0),ones(1,0),ones(1,0),[1 0])
    ??? Index exceeds matrix dimensions.

    fsparse(ones(1,0),ones(1,0),ones(1,0),[0 0])
    ??? Index exceeds matrix dimensions.

    fsparse(ones(1,0),ones(1,0),ones(1,0),[1 1])
    ans =
       All zero sparse: 1-by-1
  -Simple fix, added tests in spin.

* tsize.c: Works incorrectly for NaN's.
  Repeat:
    tsize(1,NaN) % produces an answer
  -Simple fix, added one test in spin.

* frepmat.m:
  Switch to || instead (L44).
  Let sizA be int32 (L52 and 57).
  -Fixed.

----------------------------------------------------------------
